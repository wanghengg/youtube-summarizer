// Background Service Worker

// LLM API é…ç½®
const DEFAULT_CONFIG = {
  apiProvider: 'openai', // 'openai', 'anthropic', 'deepseek', 'qwen', 'glm', 'kimi', 'custom'
  apiKey: '',
  apiEndpoint: 'https://api.openai.com/v1/chat/completions',
  model: 'gpt-4o-mini',
  speechRecognitionProvider: 'webspeech', // 'webspeech' or 'whisper'
  whisperEndpoint: 'https://api.openai.com/v1/audio/transcriptions',
  whisperModel: 'whisper-1'
};

// API æä¾›å•†é…ç½®
const API_PROVIDERS = {
  openai: {
    name: 'OpenAI',
    endpoint: 'https://api.openai.com/v1/chat/completions',
    models: ['gpt-4o-mini', 'gpt-4o', 'gpt-4-turbo', 'gpt-3.5-turbo'],
    type: 'openai'
  },
  anthropic: {
    name: 'Anthropic (Claude)',
    endpoint: 'https://api.anthropic.com/v1/messages',
    models: ['claude-3-5-sonnet-20241022', 'claude-3-haiku-20240307'],
    type: 'anthropic'
  },
  deepseek: {
    name: 'DeepSeek',
    endpoint: 'https://api.deepseek.com/chat/completions',
    models: ['deepseek-chat', 'deepseek-reasoner'],
    type: 'openai'
  },
  qwen: {
    name: 'é€šä¹‰åƒé—® (Qwen)',
    endpoint: 'https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions',
    models: ['qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-long'],
    type: 'openai'
  },
  glm: {
    name: 'æ™ºè°± GLM',
    endpoint: 'https://open.bigmodel.cn/api/paas/v4/chat/completions',
    models: ['glm-4-plus', 'glm-4', 'glm-4-flash', 'glm-4-long'],
    type: 'openai'
  },
  kimi: {
    name: 'Kimi (æœˆä¹‹æš—é¢)',
    endpoint: 'https://api.moonshot.cn/v1/chat/completions',
    models: ['moonshot-v1-8k', 'moonshot-v1-32k', 'moonshot-v1-128k'],
    type: 'openai'
  },
  custom: {
    name: 'è‡ªå®šä¹‰',
    endpoint: '',
    models: [],
    type: 'openai'
  }
};

// è·å–é…ç½®
async function getConfig() {
  const result = await chrome.storage.sync.get('config');
  return { ...DEFAULT_CONFIG, ...result.config };
}

// ä¿å­˜é…ç½®
async function saveConfig(config) {
  await chrome.storage.sync.set({ config: { ...DEFAULT_CONFIG, ...config } });
}

// ä½¿ç”¨ LLM ç”Ÿæˆæ€»ç»“
async function generateSummary(text, videoInfo, language) {
  const config = await getConfig();

  if (!config.apiKey) {
    throw new Error('è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® API Key');
  }

  const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹æ€»ç»“åŠ©æ‰‹ã€‚è¯·æ ¹æ®æä¾›çš„è§†é¢‘å­—å¹•å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½ç»“æ„æ¸…æ™°ã€å†…å®¹å‡†ç¡®çš„ä¸­æ–‡æ€»ç»“ã€‚

æ€»ç»“è¦æ±‚ï¼š
1. ä½¿ç”¨ä¸­æ–‡è¾“å‡º
2. åŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š
   - ğŸ“Œ æ ¸å¿ƒè¦ç‚¹ï¼ˆ3-5ä¸ªå…³é”®ç‚¹ï¼‰
   - ğŸ“ å†…å®¹æ‘˜è¦ï¼ˆ200-300å­—çš„è¯¦ç»†æ€»ç»“ï¼‰
   - ğŸ¯ ä¸»è¦è§‚ç‚¹æˆ–ç»“è®º
   - ğŸ’¡ å€¼å¾—å…³æ³¨çš„ç»†èŠ‚æˆ–äº®ç‚¹

è¯·ç¡®ä¿æ€»ç»“å‡†ç¡®åæ˜ åŸè§†é¢‘å†…å®¹ï¼Œä¸è¦æ·»åŠ åŸæ–‡ä¸­æ²¡æœ‰çš„ä¿¡æ¯ã€‚`;

  const userPrompt = `è§†é¢‘æ ‡é¢˜ï¼š${videoInfo.title || 'æœªçŸ¥'}
ä½œè€…ï¼š${videoInfo.author || 'æœªçŸ¥'}
å­—å¹•è¯­è¨€ï¼š${language}

å­—å¹•å†…å®¹ï¼š
${text}

è¯·ç”Ÿæˆä¸­æ–‡æ€»ç»“ï¼š`;

  // æ ¹æ® API æä¾›å•†æ„å»ºä¸åŒçš„è¯·æ±‚
  const providerConfig = API_PROVIDERS[config.apiProvider] || API_PROVIDERS.custom;

  if (providerConfig.type === 'anthropic') {
    return await callAnthropicAPI(config, systemPrompt, userPrompt);
  } else {
    return await callOpenAIAPI(config, systemPrompt, userPrompt);
  }
}

// è°ƒç”¨ OpenAI å…¼å®¹ API
async function callOpenAIAPI(config, systemPrompt, userPrompt) {
  const requestBody = {
    model: config.model,
    messages: [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt }
    ],
    temperature: 0.7,
    max_tokens: 2000
  };

  const response = await fetch(config.apiEndpoint, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${config.apiKey}`
    },
    body: JSON.stringify(requestBody)
  });

  if (!response.ok) {
    const errorData = await response.json().catch(() => ({}));
    throw new Error(`API è¯·æ±‚å¤±è´¥: ${response.status} - ${errorData.error?.message || response.statusText}`);
  }

  const data = await response.json();
  return data.choices[0].message.content;
}

// è°ƒç”¨ Anthropic API
async function callAnthropicAPI(config, systemPrompt, userPrompt) {
  const requestBody = {
    model: config.model,
    max_tokens: 2000,
    system: systemPrompt,
    messages: [
      { role: 'user', content: userPrompt }
    ]
  };

  const response = await fetch(config.apiEndpoint, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-api-key': config.apiKey,
      'anthropic-version': '2023-06-01'
    },
    body: JSON.stringify(requestBody)
  });

  if (!response.ok) {
    const errorData = await response.json().catch(() => ({}));
    throw new Error(`API è¯·æ±‚å¤±è´¥: ${response.status} - ${errorData.error?.message || response.statusText}`);
  }

  const data = await response.json();
  return data.content[0].text;
}

// ä½¿ç”¨ Whisper API è¿›è¡Œè¯­éŸ³è¯†åˆ«
async function transcribeAudio(audioBase64, mimeType) {
  const config = await getConfig();

  if (!config.apiKey) {
    throw new Error('è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® API Key');
  }

  // å°† base64 è½¬æ¢ä¸º Blob
  const binaryString = atob(audioBase64);
  const bytes = new Uint8Array(binaryString.length);
  for (let i = 0; i < binaryString.length; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  const audioBlob = new Blob([bytes], { type: mimeType });

  // åˆ›å»º FormData
  const formData = new FormData();
  formData.append('file', audioBlob, 'audio.webm');
  formData.append('model', config.whisperModel);
  formData.append('response_format', 'text');

  const response = await fetch(config.whisperEndpoint, {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${config.apiKey}`
    },
    body: formData
  });

  if (!response.ok) {
    const errorData = await response.json().catch(() => ({}));
    throw new Error(`è¯­éŸ³è¯†åˆ«å¤±è´¥: ${response.status} - ${errorData.error?.message || response.statusText}`);
  }

  const text = await response.text();
  return text;
}

// ç›‘å¬æ¥è‡ª popup çš„æ¶ˆæ¯
chrome.runtime.onMessage.addListener((request, sender, sendResponse) => {
  if (request.action === 'generateSummary') {
    generateSummary(request.text, request.videoInfo, request.language)
      .then(summary => {
        sendResponse({ success: true, summary: summary });
      })
      .catch(error => {
        sendResponse({ success: false, error: error.message });
      });
    return true;
  }

  if (request.action === 'transcribeAudio') {
    transcribeAudio(request.audioData, request.mimeType)
      .then(text => {
        sendResponse({ success: true, text: text });
      })
      .catch(error => {
        sendResponse({ success: false, error: error.message });
      });
    return true;
  }

  if (request.action === 'getConfig') {
    getConfig().then(config => {
      // ä¸è¿”å›å®Œæ•´çš„ API Keyï¼Œåªè¿”å›æ˜¯å¦å·²é…ç½®
      sendResponse({
        success: true,
        config: {
          ...config,
          apiKey: config.apiKey ? '******' : '',
          hasApiKey: !!config.apiKey
        },
        providers: API_PROVIDERS
      });
    });
    return true;
  }

  if (request.action === 'saveConfig') {
    saveConfig(request.config)
      .then(() => {
        sendResponse({ success: true });
      })
      .catch(error => {
        sendResponse({ success: false, error: error.message });
      });
    return true;
  }

  if (request.action === 'pageLoaded') {
    // å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ é¡µé¢åŠ è½½åçš„å¤„ç†é€»è¾‘
    console.log('YouTube è§†é¢‘é¡µé¢å·²åŠ è½½:', request.videoId);
    return false;
  }
});

// å®‰è£…æ—¶åˆå§‹åŒ–é…ç½®
chrome.runtime.onInstalled.addListener(() => {
  getConfig().then(config => {
    saveConfig(config);
  });
  console.log('YouTube å­—å¹•æ€»ç»“åŠ©æ‰‹å·²å®‰è£…');
});
